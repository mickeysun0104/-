{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.listdir(r'C:\\Users\\micky\\Downloads\\CleanTrack\\CleanTrack')\n",
    "filename\n",
    "df = pd.DataFrame()\n",
    "for file in filename:\n",
    "    label = file.split('.')[0]\n",
    "    \n",
    "    wavfile = r'C:\\Users\\micky\\Downloads\\CleanTrack\\CleanTrack\\{}'.format(file)\n",
    "    wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
    "\n",
    "    # Downsampling\n",
    "    # wave = wave[::3]\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=44100, n_mfcc=32, hop_length=int(0.01*44100), n_fft=int(0.025*44100))\n",
    "    tmp = pd.DataFrame(mfcc).T.head(24000)\n",
    "    tmp['target'] = label\n",
    "    if file == 'bus.wav':\n",
    "        df = tmp\n",
    "    else:\n",
    "        df = pd.concat([df, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "#設定input長相\n",
    "# g_size * rows = 72000\n",
    "# each_cat = rows / 3\n",
    "\n",
    "# 輸入(rows) 張 (g_size*32) 的音訊片，每類有each_cat張\n",
    "g_size = 80\n",
    "rows = 900\n",
    "each_cat = 300\n",
    "\n",
    "X = df.iloc[:, :-1].values.reshape(rows, g_size, 32, 1)\n",
    "y = np.array([0]*each_cat + [1]*each_cat + [2]*each_cat)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y_hot, test_size=0.30, random_state=1, stratify=y)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cvscores = []\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, verbose=2)\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # 類別變數轉為 one-hot encoding\n",
    "    y_train_hot = to_categorical(y_train)\n",
    "    y_test_hot = to_categorical(y_test)\n",
    "\n",
    "    # 建立簡單的線性執行的模型\n",
    "    model = Sequential()\n",
    "    # 建立卷積層，filter = 32,\n",
    "    # Kernal Size: 4x4, \n",
    "    # Activation function: relu\n",
    "    model.add(Conv2D(64, kernel_size=(4, 4), activation='relu', input_shape=(g_size, 32, 1)))\n",
    "    # 建立池化層，池化大小=4x4\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    # Dropout層隨機斷開輸入神經元，用於防止過度擬合，斷開比例:0.25\n",
    "    model.add(Dropout(0.25))\n",
    "    # Flatten層把多維的輸入一維化，常用在從卷積層到全連接層的過渡\n",
    "    model.add(Flatten())\n",
    "    # 全連接層: 128個 output\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Output layer\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # 選擇損失函數、優化方法及成效衡量方式\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy'])\n",
    "            \n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, y_train_hot, epochs=500, batch_size=32, verbose=2, callbacks=[early_stop])\n",
    "        \n",
    "    # loss plot\n",
    "    # pd.DataFrame(history.history['loss'], columns=['train']).plot()\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(256, activation='relu', input_shape=(80*32,)))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(128, activation='relu'))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(64, activation='relu'))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(3, activation='softmax'))\n",
    "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\n",
    "\n",
    "def get_target(num):\n",
    "    bus = []\n",
    "    river = []\n",
    "    gym = []\n",
    "    for i in range(1, num+1):\n",
    "        bus.append('bus')\n",
    "        river.append('river')\n",
    "        gym.append('gym')\n",
    "    for i,j in enumerate([bus, gym, river]):\n",
    "        if i == 0:\n",
    "            temp = pd.DataFrame(j, columns=['target'])\n",
    "        else:\n",
    "            temp_1 = pd.DataFrame(j, columns=['target'])\n",
    "            temp = pd.concat([temp, temp_1], axis=0)\n",
    "    return temp\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "X = X.reshape(-1,80*32)\n",
    "y = get_target(300)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "y_train = pd.get_dummies(y_train).values\n",
    "y_test = pd.get_dummies(y_test).values\n",
    "\n",
    "nn.fit(X_train, y_train, epochs=100,batch_size=32, validation_split = 0.2, callbacks=[early_stop])\n",
    "nn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "sample = df.drop('target',axis=1)\n",
    "sample=sample.values.reshape((900,80,32))\n",
    "X_train = np.concatenate((sample[0:210], sample[300:510], sample[600:810]))\n",
    "X_test = np.concatenate((sample[210:300], sample[510:600], sample[810:900]))\n",
    "y = pd.get_dummies(df.iloc[:, -1])\n",
    "y_train = pd.concat([y.iloc[0:210,:], y.iloc[24000:24210,:], y.iloc[48000:48210,:]])\n",
    "y_test = pd.concat([y.iloc[0:90,:], y.iloc[24000:24090,:], y.iloc[48000:48090,:]])\n",
    "\n",
    "# 建立簡單的線性執行的模型\n",
    "model = Sequential()\n",
    "# 添加第一層LSTM\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 32)))\n",
    "model.add(Dropout(0.2))\n",
    "# 添加第二層LSTM\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 添加第三層LSTM\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 3, activation='softmax'))\n",
    "model.summary()\n",
    "# Compiling\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 進行訓練\n",
    "model.fit(X_train, y_train, epochs = 20, batch_size = 32)\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6d942f08859e5babc70b536aeb59037957cf8e1bc5da73e43bb15de24165b28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
